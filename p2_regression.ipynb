{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/deepsense_header.png)\n",
    "\n",
    "# Machine Learning and Big Data\n",
    "\n",
    "A course by [deepsense.io](http://deepsense.io/).\n",
    "\n",
    "# Part 2: Linear Regression \n",
    "\n",
    "A simple yet powerful tool for predicting numerical values.\n",
    "\n",
    "* Fast\n",
    "* Easy to start\n",
    "* With an easy interpretation\n",
    "* Can be used for variable selection\n",
    "* Can be tweaked a lot\n",
    "\n",
    "![](imgs/wikipedia_correlation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# plots\n",
    "import seaborn as sns\n",
    "\n",
    "# some other plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# so the plots appear inline\n",
    "%matplotlib inline\n",
    "\n",
    "# numerics (e.g. logarithm)\n",
    "import numpy as np\n",
    "\n",
    "# regression models from scikit-learn\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.cross_validation import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "df = pd.read_csv(\"data/Bike-Sharing-Dataset/day.csv\", parse_dates=[\"dteday\"], index_col=\"dteday\")\n",
    "\n",
    "# removing outliers (Linear Regression is sensitive to them!)\n",
    "df = df.query(\"temp - atemp < 0.2\").query(\"cnt > 100\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression for 2 variables\n",
    "\n",
    "The simplest case for Linear Regression - using a single variable to predict another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.jointplot allows us to plot two variables as scatterplot with histograms\n",
    "# option `kind='reg'` adds a regression line\n",
    "sns.jointplot('temp', 'atemp', df, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some other pairs are less correlated\n",
    "sns.jointplot('casual', 'atemp', df, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "X = df[['temp']]\n",
    "\n",
    "# output\n",
    "Y = df['atemp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X is a DataFrame with one column\n",
    "# in general, we can use as many columns as we wish\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Y is a Series (just a column)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a Linear Regression object\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training classifier with data \n",
    "reg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linear regression coefficient\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linear regression constant term\n",
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means that we use the following formula:\n",
    "\n",
    "$$\\text{atemp} = 0.887 \\cdot \\text{temp} + 0.037$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict atemp for temp=0.5\n",
    "reg.predict(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict atemp for temps: 0.5, 0.2 and -0.3\n",
    "reg.predict([[0.5], [0.2], [-0.3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Always we need to test our predictions.\n",
    "\n",
    "* plotting\n",
    "* cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions for the actual data\n",
    "Y_pred = reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame({\"actual\": Y, \"predicted\": Y_pred})\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot('actual', 'predicted', df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# R^2\n",
    "# from 0 (predicting mean value) to 1 (perfect prediction)\n",
    "# it CAN be negative for predictions being worse than guessing \n",
    "reg.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "# splitting, where 75% data goes for training and 25% for testing the prediction\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we fit on the training set\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, Y_train)  \n",
    "\n",
    "# we can test on the same set\n",
    "print(\"R^2 on the train set:\")\n",
    "print(reg.score(X_train, Y_train))\n",
    "\n",
    "# but the actual predictive value is measured by the test set, never seen during fitting\n",
    "print(\"\\nR^2 on the test set:\")\n",
    "print(reg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* Modify the above (starting from the lines defining `X` and `Y`) so it predicts `casual` (the number of casual users) based on `atemp` (the feeling temperature)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More variables\n",
    "\n",
    "Almost always we want to use more parameters than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input\n",
    "X = df[['temp', 'atemp', 'hum', 'windspeed', 'weathersit', 'weekday']].copy()\n",
    "\n",
    "# output\n",
    "Y = df['casual']\n",
    "\n",
    "# splitting for cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "# regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "\n",
    "print(\"R^2 on the train set:\")\n",
    "print(reg.score(X_train, Y_train))\n",
    "\n",
    "print(\"\\nR^2 on the test set:\")\n",
    "print(reg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame({\"actual_casual\": Y, \"predicted_casual\": reg.predict(X)})\n",
    "sns.jointplot('actual_casual', 'predicted_casual', df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting the importance of variables\n",
    "coeffs = pd.Series(reg.coef_, index=X.columns)\n",
    "coeffs_normalized = coeffs * X.std() / Y.std()\n",
    "coeffs_normalized.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* Removing which column in `X` changes the result the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross-validation\n",
    "\n",
    "Note that a single random train test split can produce unstable scores. We will perform multiple splits by [K-fold cross-validation](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html#sklearn.cross_validation.KFold) to account for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "cv = KFold(n = X.shape[0], n_folds=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "for train_index, test_index in cv:\n",
    "    X_train = X.iloc[train_index] \n",
    "    Y_train = Y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index] \n",
    "    Y_test = Y.iloc[test_index]\n",
    "    # regression\n",
    "    reg.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"---------------------\")\n",
    "    print(\"R^2 on the train set:\")\n",
    "    print(reg.score(X_train, Y_train))\n",
    "\n",
    "    print(\"\\nR^2 on the test set:\")\n",
    "    score = reg.score(X_test, Y_test)\n",
    "    print(score)\n",
    "    test_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming variables\n",
    "\n",
    "Sometimes transforming variables improves fit.\n",
    "\n",
    "* logarithmic scale\n",
    "* dummy variables\n",
    "* normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sqrt(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log10(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* What is the logarithm (base 10) of: `1000000`, `0.001`, `-3`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some artificial data\n",
    "v1 = np.random.rand(100)\n",
    "v2 = np.exp(2 * v1 + 0.2 * np.random.randn(100))\n",
    "v3 = np.exp(4 * v1 + 0.3 * np.random.randn(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(v1, v2, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.log10 variable[s]\n",
    "plt.plot(v3, v1, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.log10 variable[s]\n",
    "plt.plot(v2, v3, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* Apply logarithm for some variables (i.e write `np.log10(vx)` instead of `vx`) when it makes the plot more linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we copy a dataframe, so we can safely modify it\n",
    "df_t = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_t.plot(kind='scatter', x='temp', y='casual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_t.plot(kind='scatter', x='temp', y='casual', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this plot may be convenient for testing transformations\n",
    "plt.plot(df_t[\"atemp\"], np.sqrt(df_t[\"casual\"]), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logarithmic scalling of a variable\n",
    "df_t[\"casual\"].apply(np.log10).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# changing a variables for good\n",
    "df_t[\"casual\"] = np.log10(df_t[\"casual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# so it is converted\n",
    "df_t[\"casual\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# changing categorical variables into binary\n",
    "pd.get_dummies(df_t[[\"temp\", \"weekday\"]], columns=['weekday']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalzation\n",
    "df_t[\"cnt_norm\"] = (df[\"cnt\"] - df[\"cnt\"].mean()) / df[\"cnt\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# it has mean 0 (up to numerical precission)\n",
    "df_t[\"cnt_norm\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and standard deviation 1 (again, up to the  numerical precission)\n",
    "df_t[\"cnt_norm\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations - and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's see how it works in practice\n",
    "\n",
    "# input\n",
    "X = df[['temp', 'atemp', 'hum', 'windspeed', 'weathersit', 'weekday']].copy()\n",
    "X = pd.get_dummies(X, columns=['weekday'])\n",
    "X = X.drop('weekday_1', axis=1)\n",
    "\n",
    "# output\n",
    "Y = df['casual'].apply(np.log10)\n",
    "\n",
    "# splitting for cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "# regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "\n",
    "print(\"R^2 on the train set:\")\n",
    "print(reg.score(X_train, Y_train))\n",
    "\n",
    "print(\"\\nR^2 on the test set:\")\n",
    "print(reg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting the importance of variables\n",
    "coeffs = pd.Series(reg.coef_, index=X.columns)\n",
    "coeffs_normalized = coeffs * X.std() / Y.std()\n",
    "coeffs_normalized.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame({\"actual_casual\": Y, \"predicted_casual\": reg.predict(X)})\n",
    "sns.jointplot('actual_casual', 'predicted_casual', df_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* Try turning dummy variables on and off.\n",
    "* Try `np.sqrt` instead of `np.log10`.\n",
    "\n",
    "It is better? Worse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on the logarithm\n",
    "\n",
    "For a positive variable, we can run regression on its logarithm rather original value. Then the fitting reads: \n",
    "\n",
    "$$\\ln(y) = a_1 x_1 + a_2 x_2 + a_3 x_3 + b$$\n",
    "\n",
    "The result can be transformed into\n",
    "\n",
    "$$y = B A_1^{x_1} A_2^{x_2} A_3^{x_3}$$\n",
    "\n",
    "so:\n",
    "\n",
    "  * $y$ is always positive,\n",
    "  * each factor $x_i$ *multiplies* rather than *adds to* the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions\n",
    "\n",
    "Sometimes we need to take into account interactions between two (or more) variables. Interactions are applicable when we want to model extra dependency between variables. They are modelled by introducing pairwise feature multiplications in a model:\n",
    "\n",
    "$$y = b + a_1 x_1 + a_2 x_2 + \\boldsymbol{a_3 x_1 x_2}$$\n",
    "\n",
    "This can be rewritten as \n",
    "\n",
    "$$y = b + a_1 x_1 + \\boldsymbol{(a_2 + a_3 x_1)x_2}.$$\n",
    "\n",
    "We may interpret it as **a change of the influence** of variable $x_2$ on $y$ **depending on** the level of variable $x_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "win = [('win', 'yes'), ('win', 'no')]\n",
    "son = [('scored', 'yes'), ('scored', 'no')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interactions = pd.DataFrame([[20, 5], [3, 0]], index=pd.MultiIndex.from_tuples(win), columns=pd.MultiIndex.from_tuples(son))\n",
    "interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And back to the real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_int = df.copy()\n",
    "for col in df:\n",
    "    df_int[col + \"_x_\" \"workingday\"] = df[col] * df[\"workingday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_int.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input\n",
    "X = df[['temp', 'atemp', 'hum', 'windspeed', 'weathersit', 'weekday']].copy()\n",
    "X = pd.get_dummies(X, columns=['weekday'])\n",
    "X = X.drop('weekday_2', axis=1)\n",
    "\n",
    "cols = X.columns \n",
    "\n",
    "for col1 in cols:\n",
    "    for col2 in cols:\n",
    "        if col1 <= col2 and not (col1.startswith(\"weekday\") and col2.startswith(\"weekday\")):\n",
    "            X[col1 + '_x_' + col2] = X[col1] * X[col2]\n",
    "            \n",
    "# output\n",
    "Y = df['casual'].apply(np.log10)\n",
    "\n",
    "# splitting for cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=15)\n",
    "\n",
    "# regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "\n",
    "print(\"R^2 on the train set:\")\n",
    "print(reg.score(X_train, Y_train))\n",
    "\n",
    "print(\"\\nR^2 on the test set:\")\n",
    "print(reg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with  LASSO Regularization\n",
    "\n",
    "* still Linear Regression\n",
    "* tries to avoid spurious correlations (overfitting)\n",
    "\n",
    "Typical Linear Regression minimizes square deviation from  (so-called least-square fitting)\n",
    "\n",
    "$$\\sum_i (y_i - \\bar{y}_i)^2$$\n",
    "\n",
    "LASSO Linear Regression minimizes the above plus the absolute value of all regression coefficients\n",
    "\n",
    "$$\\sum_i (y_i - \\bar{y}_i)^2 + \\lambda \\sum_j |a_j|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input\n",
    "X = df[['temp', 'atemp', 'hum', 'windspeed', 'weathersit', 'weekday']].copy()\n",
    "X = pd.get_dummies(X, columns=['weekday'])\n",
    "# X = X.drop('weekday_2', axis=1)  # we don't need that in LASSO\n",
    "\n",
    "cols = X.columns \n",
    "\n",
    "for col1 in cols:\n",
    "    for col2 in cols:\n",
    "        if col1 <= col2 and not (col1.startswith(\"weekday\") and col2.startswith(\"weekday\")):\n",
    "            X[col1 + '_x_' + col2] = X[col1] * X[col2]\n",
    "             \n",
    "# output\n",
    "Y = df['casual'].apply(np.log10)\n",
    "\n",
    "# splitting for cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=15)\n",
    "\n",
    "# LASSO Linear Regression instead of an ordinary one\n",
    "lasso = LassoCV(normalize=True, max_iter=10000)\n",
    "lasso.fit(X_train, Y_train)\n",
    "\n",
    "print(\"R^2 on the train set:\")\n",
    "print(lasso.score(X_train, Y_train))\n",
    "\n",
    "print(\"\\nR^2 on the test set:\")\n",
    "print(lasso.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LASSO turns many coefficients in zeros\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting the importance of variables\n",
    "coeffs = pd.Series(lasso.coef_, index=X.columns)\n",
    "coeffs.plot(kind=\"bar\", figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "* Use in the above:\n",
    "    * remove interactions,\n",
    "    * use `season` and `weathersit` with dummy variables,\n",
    "    * ★ add interaction between only between `workingday` and other variables.\n",
    "* ★ Predict `casual` users based on `registered`  (but not `cnt`) and `workingday`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest Regression\n",
    "\n",
    "Let's try a different model - [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor). It works for both regression and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a random forest regressor\n",
    "rfr = RandomForestRegressor(n_estimators=50, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.drop([\"cnt\", \"mnth\", \"registered\", \"casual\", \"instant\"], axis=1)\n",
    "Y = df[\"casual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# don't do that!\n",
    "# for Random Forest score on the training set is (almost) always very high\n",
    "rfr.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# on test set it is lower\n",
    "rfr.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alternatively, instead of cross validating\n",
    "# we can estimate score by measuring so-called out-of-box score\n",
    "rfr.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature (variable) importance\n",
    "rfr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# but we want to plot it\n",
    "pd.Series(rfr.feature_importances_, index=X.columns).plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "* What is the feature importance if you remove:\n",
    "    * `temp`?\n",
    "    * `temp` and `atemp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
