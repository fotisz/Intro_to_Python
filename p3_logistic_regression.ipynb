{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/deepsense_header.png)\n",
    "\n",
    "# Machine Learning and Big Data\n",
    "\n",
    "A course by [deepsense.io](http://deepsense.io/).\n",
    "\n",
    "## Part 3: Logistic Regression\n",
    "\n",
    "Linear regression analogue for:\n",
    "\n",
    "* classification\n",
    "* estimating probabilities\n",
    "\n",
    "![](imgs/wikipedia_logistic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# again, let us use the Bike Sharing Dataset\n",
    "df = pd.read_csv(\"data/Bike-Sharing-Dataset/day.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# warning: official description was wrong!\n",
    "seasons = {1: \"winter\", 2: \"spring\", 3: \"summer\", 4: \"fall\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recoding seasons\n",
    "df['season'] = df['season'].map(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grouping by \"seasons\", selecting \"cnt\" columns and then taking mean \n",
    "df.groupby(\"season\")[\"cnt\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's define some colors we will be using\n",
    "colors = {\"winter\": \"#5555dd\", \"spring\": \"#55dd55\", \"summer\": \"#bbbb33\", \"fall\": \"#dd5555\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temperatures in seasons\n",
    "for name, df_part in df.groupby(\"season\")[\"temp\"]:\n",
    "    sns.distplot(df_part, hist=False, label=name, color=colors[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# biker count by season\n",
    "for name, df_part in df.groupby(\"season\")[\"cnt\"]:\n",
    "    sns.distplot(df_part, hist=False, label=name, color=colors[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "* Plot humidity by season.\n",
    "* Plot casual and (on a separate plot) registered users by season.\n",
    "* â˜… Plot usage by weekday.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression for 2 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a logistic regression classifier\n",
    "# parameter C is related to regularization;\n",
    "# in short, it bounds the maximal steepness of the logistic function \n",
    "lr = LogisticRegression(C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "X = df[[\"cnt\"]]\n",
    "\n",
    "# output\n",
    "Y = df[\"season\"] == \"winter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# splitting the dataset for cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training Linear Regression on data\n",
    "lr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# score - percent of correct answers\n",
    "# on the train set\n",
    "lr.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# score - percent of correct answers\n",
    "# on the test set\n",
    "lr.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, df_part in df.groupby(\"season\")[\"cnt\"]:\n",
    "    sns.distplot(df_part, hist=False, label=name, color=colors[name])\n",
    "\n",
    "# vertical line for each logistic regression predicts the boundary\n",
    "plt.vlines(-lr.intercept_[0]/lr.coef_[0,0], 0, 0.00035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# probability (logistic function) vs binary prediction \n",
    "X_grid = np.linspace(-3000, 10000, 100).reshape(100, 1)\n",
    "logistic_df = pd.DataFrame({\"winter prediction\": lr.predict(X_grid),\n",
    "                            \"winter probability\": lr.predict_proba(X_grid)[:,1]},\n",
    "                            index=X_grid.reshape(100))\n",
    "\n",
    "logistic_df.sort_index().plot()\n",
    "plt.ylim(-0.1, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one more plot - this time with histograms and absolute counts\n",
    "\n",
    "df.query(\"season == 'winter'\")[\"cnt\"] \\\n",
    "  .hist(label=seasons[1], color=colors['winter'], alpha=0.5, range=(0, 10000), bins=40)\n",
    "\n",
    "df.query(\"season != 'winter'\")[\"cnt\"] \\\n",
    "  .hist(label=\"Not winter\", color=\"grey\", alpha=0.5, range=(0, 10000), bins=40)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "threshold = -lr.intercept_[0]/lr.coef_[0,0]\n",
    "width = 1/lr.coef_[0,0]\n",
    "plt.vlines(threshold, 0, 50)\n",
    "plt.vlines(threshold - width, 0, 50, linestyles='dashed')\n",
    "plt.vlines(threshold + width, 0, 50, linestyles='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# more detailed score\n",
    "confusion_matrix(Y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# confused?\n",
    "# let's plot it!\n",
    "\n",
    "df_confusion = pd.DataFrame(confusion_matrix(Y_test, lr.predict(X_test)))\n",
    "\n",
    "df_confusion.index = [\"not winter\", \"winter\"]\n",
    "df_confusion.index.name = \"true value\"\n",
    "\n",
    "df_confusion.columns = [\"not winter\", \"winter\"]\n",
    "df_confusion.columns.name = \"predicted value\"\n",
    "\n",
    "sns.heatmap(df_confusion, linewidths=3, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More variables may help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.pairsplot is useful for showing many scatter plots at once \n",
    "sns.pairplot(df,\n",
    "             vars=[\"hum\", \"temp\", \"atemp\", \"casual\", \"registered\"],\n",
    "             hue=\"season\",\n",
    "             palette=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=100)\n",
    "\n",
    "X = df[[\"casual\", \"registered\", \"weekday\", \"yr\"]].copy()\n",
    "\n",
    "X['casual'] = np.log10(X['casual'])\n",
    "\n",
    "X = (X - X.mean())/X.std()\n",
    "\n",
    "\n",
    "Y = (df[\"season\"] == \"winter\")\n",
    "\n",
    "# splitting the dataset for cross validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "# training\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "# score \n",
    "print(\"Train score is: {:.3f}\".format(lr.score(X_train, Y_train)))\n",
    "print(\"Test score is:  {:.3f}\".format(lr.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we used normalized variables\n",
    "coeffs = pd.Series(lr.coef_[0], index=X.columns)\n",
    "coeffs.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# again, a confusion matrix\n",
    "df_confusion = pd.DataFrame(confusion_matrix(Y_test, lr.predict(X_test)))\n",
    "\n",
    "df_confusion.index = [\"not winter\", \"winter\"]\n",
    "df_confusion.index.name = \"true value\"\n",
    "\n",
    "df_confusion.columns = [\"not winter\", \"winter\"]\n",
    "df_confusion.columns.name = \"predicted value\"\n",
    "\n",
    "sns.heatmap(df_confusion, linewidths=3, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "* Use other variables and their scalings to improve the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
